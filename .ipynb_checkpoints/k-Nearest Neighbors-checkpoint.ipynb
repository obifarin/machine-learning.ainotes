{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>\n",
    "<img src=\"datasets/AInote_logo.jpeg\" height=\"1000\" width=\"700\" />\n",
    "    \n",
    "# k-Nearest Neighbors Classifier\n",
    "\n",
    "Author: Olatomiwa Bifarin. <br>\n",
    "PhD Candidate Biochemistry and Molecular Biology <br>\n",
    "@ The University of Georgia\n",
    "\n",
    "_This is a draft copy, a work in progress_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Look up the coding exercise on Inner products and distance on the pca coursera file to build a KNN_classifier from scratch_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Content\n",
    "\n",
    "1.  [Definition](#1) <br>\n",
    "2.  [A Simpified Example](#2) <br>\n",
    "    2.1 [Naive k-NN](#2.1) <br>\n",
    "    2.2 [A weighted k-NN](#2.2) <br>\n",
    "3.  [Scikit learn Implementation](#3) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definition\n",
    "<a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Nearest Neighbors (kNN) is one of the simplest and intuitive machine learning algorithm out there. It simply _argues_ that a new sample should be classified based on the identity of the _k_ (to be defined) nearest neighbors. In order words `neighbors should have the same identity`. Note that this is a kind of inductive bias, that is, this is how it generalizes. Another inductive bias in a naive k-NN classifier is the following: `all features are 'created' equally.` Note that there are other types of k-NN that handle the later bias for example, weighted k-NN. \n",
    "\n",
    "Once you get the idea behind k-NN, then it is not hard to figure out that the algorithm isn't learning anything _per se_. All it's during here is storing training examples, and then classifying test data based on the proximity heuristics defined. This will also hint the reader that classification will be potentially. \n",
    "\n",
    "Two hyperparameters are important for tuning a naive k-NN classifier. 1) the value of _k_, 2) the distance measure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Popular Distance Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  L2 distance (Euclidean distance)\n",
    "\n",
    "$$\n",
    "d(x,y) = \\sqrt{\\sum_{i=1}^{n} (x-y)^2}\n",
    "$$\n",
    "\n",
    "-  L1 distance \n",
    "\n",
    "$$\n",
    "d(x,y) = \\sum_{i=1}^{n} |x - y|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 _k_ and Decision Boundaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A Simplified Example\n",
    "<a id=\"2\"></a>\n",
    "_Reference: The example used in this session was an assignment question for a ARTI 8950 class I offered at the University of Georgia (Spring 2020) taught by Dr Sheng Li. All Solutions are mine._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we have 6 samples ($洧논_{1}$ , 洧녰 = 1, ... ,6) from two classes (A and B). We aim to classify a test sample $洧논_{t}$ by using the k-NN classification method. The cosine similarities between $洧논_{t}$ and $洧논_{i}$ are provided in the table below.\n",
    "\n",
    "| Sample| cos($x_i$ $x_d$) | Class Label|\n",
    "| --- | --- | --- |\n",
    "| 1| 1.00  | A|\n",
    "| 2| 0.95  | B|\n",
    "| 3| 0.94  | B|\n",
    "| 4| 0.45  | A|\n",
    "| 5| 0.40 | A|\n",
    "| 6| 0.39  | B|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Naive k-NN\n",
    "<a id=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume that we use the cosine as a distance metric, i.e., the higher the cosine, the closer are two samples.\n",
    "For the test sample $洧논_{t}$, after selecting k nearest neighbors $洧논_{n1}$, ... , $洧논_{nk}$ from the dataset, two scoring functions can be used to predict the class label.\n",
    "\n",
    "Scoring by simple majority vote:\n",
    "\n",
    "$$ \\text{Score}(A,x_{t}) = \\sum_{j=1} I_A(x_{nj})$$\n",
    "\n",
    "$$ I_A(x_{nj}) = \n",
    "\\begin{cases}\n",
    "0 & \\text{class label} \\neq A \\\\\n",
    "1 & \\text{class label} = A\n",
    "\\end{cases}$$\n",
    "\n",
    "$$ \\text{Score}(B,x_{t}) = \\sum_{j=1} I_B(x_{nj})$$\n",
    "\n",
    "$$ I_B(x_{nj}) = \n",
    "\\begin{cases}\n",
    "0 & \\text{class label} \\neq B \\\\\n",
    "1 & \\text{class label} = B\n",
    "\\end{cases}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = {'Sample': [1, 2, 3, 4, 5, 6], \n",
    "     'cos(xd, xi)': [1, 0.95, 0.94, 0.45, 0.4, 0.39], \n",
    "     'Class Label': ['A', 'B', 'B', 'A', 'A', 'B']}\n",
    "df_knn = pd.DataFrame(data=knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_knn(k, distance):\n",
    "    neigbors = [] # List to store neigbors\n",
    "    aa = list(distance) # list of the distance between x_t and x_i\n",
    "    # arrange list in descending order\n",
    "    aa.sort(reverse=True) # recall that the higher the cosine, the closer are two samples. \n",
    "    aa = aa[:k] # Select the top k i.e. the k-neigbors's distances\n",
    "    for i in aa: # loop through the content of aa\n",
    "        # select the class membership corresponding to the k-neigbors's distances\n",
    "        b = list(df_knn.loc[df_knn['cos(xd, xi)'] == i, 'Class Label']) \n",
    "        neigbors.append(b) # append class membership to list\n",
    "    list(neigbors) # remove superflous information from list\n",
    "    ax = [val for sublist in neigbors for val in sublist] #flatten out the list\n",
    "    scores=Counter(ax)\n",
    "    return ax, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) By using k-NN classification with simple majority vote and setting 洧녲 = 3, which class label would be assigned to $洧논_t$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A', 'B', 'B'], Counter({'A': 1, 'B': 2}))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_knn(3, df_knn['cos(xd, xi)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\text{Given that }  I_B(x_{nj}) > I_A(x_{nj}) \\text{, }x_t \\text{will be classified as } B $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) By using k-NN classification with simple majority vote and setting 洧녲 = 5, which class label would be assigned to $洧논_t$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A', 'B', 'B', 'A', 'A'], Counter({'A': 3, 'B': 2}))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_knn(5, df_knn['cos(xd, xi)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\text{Given that }  I_B(x_{nj}) < I_A(x_{nj}) \\text{, }x_t \\text{will be classified as } A $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 A Weighted k-NN\n",
    "<a id=\"2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scikit learn Implementation\n",
    "<a id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Resources\n",
    "-  A course in machine learning (CIML) k-NN Chapter\n",
    "-  Reference for example: class in ARTI 8950\n",
    "-  sklearn knn classifier page\n",
    "-  mlcouse.ai notebook on k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
